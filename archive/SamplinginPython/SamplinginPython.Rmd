---
title: "Sampling in Python"
subtitle: "James Chapman"
date: "05 July 2022"
author:
  - name: "Tran Thanh Dat - International University"
output:
  rmdformats::robobook:
    thumbnails: true
    lightbox: true
    gallery: true
    use_bookdown: true
---

***

<style>

h1,h2,h3,h4,h5,h6,h {
  font-family: Futura;
}

body {
  font-family: "Georgia";
  text-align: justify;
}

p {
  font-family: "Georgia";
  text-indent: 30px;
  color: black;
  font-style: normal;
}
</style>

```{r klippy, echo=FALSE, include=TRUE}
klippy::klippy()
```

**Course Description**


<p class="course__description">Sampling in Python is the cornerstone of inference statistics and hypothesis testing. It's a powerful skill used in survey analysis and experimental design to draw conclusions without surveying an entire population. In this Sampling in Python course, you’ll discover when to use sampling and how to perform common types of sampling—from simple random sampling to more complex methods like stratified and cluster sampling. Using real-world datasets, including coffee ratings, Spotify songs, and employee attrition, you’ll learn to estimate population statistics and quantify uncertainty in your estimates by generating sampling distributions and bootstrap distributions. Should there be further discussion, please contact us via email: dattran.hcmiu@gmail.com.</p>

# Bias Any Stretch of the Imagination

<p class="chapter__description">
    Learn what sampling is and why it is so powerful. You’ll also learn about the problems caused by convenience sampling and the differences between true randomness and pseudo-randomness.
  </p>
  
## Living the sample life



### Reasons for sampling

<div class=""><p>Sampling is an important technique in your statistical arsenal. It isn't always appropriate though—you need to know when to use it and when to work with the whole dataset.</p>
<p>Which of the following is <strong>not</strong> a good scenario to use sampling?</p></div>

<li>You've been handed one terabyte of data about error logs for your company's device.</li>
<li>You wish to learn about the travel habits of all Pakistani adult citizens.</li>
<strong><li>You've finished collecting data on a small study of the wing measurements for 10 butterflies.</li></strong>
<li>You are working to predict customer turnover on a big data project for your marketing firm.</li>

<p class="dc-completion-pane__message dc-u-maxw-100pc">Commendations on your justifications for not sampling! Ten butterflies is a small dataset, so sampling isn't useful here.</p>

### Simple sampling with pandas


<div class>
<p>Throughout this chapter, you'll be exploring song data from Spotify. Each row of this population dataset represents a song, and there are over 40,000 rows. Columns include the song name, the artists who performed it, the release year, and attributes of the song like its duration, tempo, and danceability. You'll start by looking at the durations.</p>
<p>Your first task is to sample the Spotify dataset and compare the mean duration of the population with the sample.</p>
<p><code>spotify_population</code> is available and <code>pandas</code> is loaded as <code>pd</code>.</p>
</div>
```{python,warning=F,message=F}

import pandas as pd
import pyarrow
spotify_population = pd.read_feather('https://assets.datacamp.com/production/repositories/5975/datasets/18d07c39535b900b64dc145985d9e8dfbf2ca498/spotify_2000_2020.feather')
```

<li>Sample 1000 rows from <code>spotify_population</code>, assigning to <code>spotify_sample</code>.</li>
```{python,warning=F,message=F}
# Sample 1000 rows from spotify_population
spotify_sample = spotify_population.sample(n=1000)

# Print the sample
print(spotify_sample)
```


<li>Calculate the mean duration in minutes from <code>spotify_population</code> using <code>pandas</code>.</li>
```{python,warning=F,message=F}
# Calculate the mean duration in mins from spotify_population
mean_dur_pop = spotify_population["duration_minutes"].mean()
```

<li>Calculate the mean duration in minutes from <code>spotify_sample</code> using <code>pandas</code>.</li>
```{python,warning=F,message=F}
# Calculate the mean duration in mins from spotify_sample
mean_dur_samp = spotify_sample["duration_minutes"].mean()

# Print the means
print(mean_dur_pop)
print(mean_dur_samp)
```

<p class="">Powerful point estimating! Notice that the mean song duration in the sample is similar, but not identical to the mean song duration in the whole population.</p>

### Simple sampling and calculating with NumPy


<div class>
<p>You can also use <code>numpy</code> to calculate parameters or statistics from a list or <code>pandas</code> Series.</p>
<p>You'll be turning it up to eleven and looking at the <code>loudness</code> property of each song.</p>
<p><code>spotify_population</code> is available and <code>numpy</code> is loaded as <code>np</code>.</p>
</div>

<li>Create a <code>pandas</code> Series from the <code>loudness</code> column of <code>spotify_population</code>, assigning it to <code>loudness_pop</code>.</li>
```{python,warning=F,message=F}
# Create a pandas Series from the loudness column of spotify_population
loudness_pop = spotify_population['loudness']
```
<li>Sample <code>loudness_pop</code> to get 100 random values, assigning to <code>loudness_samp</code>.</li>
```{python,warning=F,message=F}
# Sample 100 values of loudness_pop
loudness_samp = loudness_pop.sample(n=100)

# Print the sample
print(loudness_samp)
```


<li>Calculate the mean of <code>loudness_pop</code> using <code>numpy</code>.</li>
```{python,warning=F,message=F}

import numpy as np
# Calculate the mean of loudness_pop
mean_loudness_pop = np.mean(loudness_pop)
```

<li>Calculate the mean of <code>loudness_samp</code> using <code>numpy</code>.</li>
```{python,warning=F,message=F}
# Calculate the mean of loudness_samp
mean_loudness_samp = np.mean(loudness_samp)

# Print the means
print(mean_loudness_pop)
print(mean_loudness_samp)
```

<p class="">Devious means! Again, notice that the calculated value (the mean) is close but not identical in each case.</p>

## A little too convenient



### Are the findings from this sample generalizable?


<div class>
<p>You just saw how convenience sampling—collecting data using the easiest method—can result in samples that aren't representative of the population. Equivalently, this means findings from the sample are not generalizable to the population. Visualizing the distributions of the population and the sample can help determine whether or not the sample is representative of the population.</p>
<p>The Spotify dataset contains an <code>acousticness</code> column, which is a confidence measure from zero to one of whether the track was made with instruments that aren't plugged in. You'll compare the <code>acousticness</code> distribution of the total population of songs with a sample of those songs.</p>
<p><code>spotify_population</code> and <code>spotify_mysterious_sample</code> are available; <code>pandas</code> as <code>pd</code>, <code>matplotlib.pyplot</code> as <code>plt</code>, and <code>numpy</code> as <code>np</code> are loaded.</p>
</div>

<li>Plot a histogram of the <code>acousticness</code> from <code>spotify_population</code> with bins of width <code>0.01</code> from <code>0</code> to <code>1</code> using pandas <code>.hist()</code>.</li>
```{python,warning=F,message=F}

import matplotlib.pyplot as plt
# Visualize the distribution of acousticness with a histogram
spotify_population['acousticness'].hist(bins=np.arange(0, 1.01, 0.01))
plt.show()
```

```{python,warning=F,message=F}

import numpy as np
mysterious_sample = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vRap3kWpwEhSDTpqc_LrCbTQIY9qLhnpZP17axDfsGUSOV6DL_fJsqNp9vXbCAjfzrBds8c3NCJZg2f/pub?gid=709023650&single=true&output=csv')

spotify_mysterious_sample = spotify_population.loc[mysterious_sample['index'].to_numpy()]
```

<li>Update the histogram code to use the <code>spotify_mysterious_sample</code> dataset.</li>

```{python,warning=F,message=F}
# Update the histogram to use spotify_mysterious_sample
spotify_mysterious_sample['acousticness'].hist(bins=np.arange(0, 1.01, 0.01))
plt.show()
```

<div class=""><p><em>Compare the two histograms you drew.</em> Are the <code>acousticness</code> values in the sample generalizable to the general population?</p></div>

<li>Yes. Any sample should lead to a generalizable result about the population.</li>
<li>Yes. The sample selected is likely a random sample of all songs in our population.</li>
<li>No. Samples can never lead to generalizable results about the population.</li>
<strong><li>No. The acousticness samples are consistently higher than those in the general population.</li></strong>
<li>No. The acousticness samples are consistently lower than those in the general population.</li>

<p class="">Ace acouticness analysis! The <code>acousticness</code> values in the sample are all greater than <code>0.95</code>, whereas they range from <code>0</code> to <code>1</code> in the whole population.</p>

### Are these findings generalizable?


<div class>
<p>Let's look at another sample to see if it is representative of the population. This time, you'll look at the <code>duration_minutes</code> column of the Spotify dataset, which contains the length of the song in minutes.</p>
<p><code>spotify_population</code> and <code>spotify_mysterious_sample2</code> are available; <code>pandas</code>, <code>matplotlib.pyplot</code>, and <code>numpy</code> are loaded using their standard aliases.</p>
</div>

<li>Plot a histogram of <code>duration_minutes</code> from <code>spotify_population</code> with bins of width <code>0.5</code> from <code>0</code> to <code>15</code> using pandas <code>.hist()</code>.</li>

```{python,warning=F,message=F}
# Visualize the distribution of duration_minutes as a histogram
spotify_population['duration_minutes'].hist(bins=np.arange(0, 15.5, 0.5))
plt.show()
```
```{python,warning=F,message=F}

import numpy as np
mysterious_sample2 = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vRap3kWpwEhSDTpqc_LrCbTQIY9qLhnpZP17axDfsGUSOV6DL_fJsqNp9vXbCAjfzrBds8c3NCJZg2f/pub?gid=475457320&single=true&output=csv')

spotify_mysterious_sample2 = spotify_population.loc[mysterious_sample2['index'].to_numpy()]
```



<li>Update the histogram code to use the <code>spotify_mysterious_sample2</code> dataset.</li>
```{python,warning=F,message=F}
# Update the histogram to use spotify_mysterious_sample2
spotify_mysterious_sample2['duration_minutes'].hist(bins=np.arange(0, 15.5, 0.5))
plt.show()
```

<div class=""><p><em>Compare the two histograms you drew.</em> Are the duration values in the sample generalizable to the general population?</p></div>

<li>Yes. Any sample should lead to a generalizable result about the population.</li>
<strong><li>Yes. The sample selected is likely a random sample of all songs in the population.</li></strong>
<li>No. Samples can never lead to generalizable results about the population.</li>
<li>No. The duration samples are consistently higher than those in the general population.</li>
<li>No. The duration samples are consistently lower than those in the general population.</li>

<p class="">Delightful duration distribution analysis! The duration values in the sample show a similar distribution to those in the whole population, so the results are generalizable.</p>

## How does Sue do sampling?



### Generating random numbers


<div class>
<p>You've used <code>.sample()</code> to generate pseudo-random numbers from a set of values in a DataFrame. A related task is to generate random numbers that follow a statistical distribution, like the uniform distribution or the normal distribution.</p>
<p>Each random number generation function has distribution-specific arguments and an argument for specifying the number of random numbers to generate.</p>
<p><code>matplotlib.pyplot</code> is loaded as <code>plt</code>, and <code>numpy</code> is loaded as <code>np</code>.</p>
</div>

<li>Generate 5000 numbers from a uniform distribution, setting the parameters <code>low</code> to <code>-3</code> and <code>high</code> to <code>3</code>.</li>
```{python,warning=F,message=F}
# Generate random numbers from a Uniform(-3, 3)
uniforms = np.random.uniform(low=-3, high=3, size=5000)

# Print uniforms
print(uniforms)
```

<li>Generate 5000 numbers from a normal distribution, setting the parameters <code>loc</code> to <code>5</code> and <code>scale</code> to <code>2</code>.</li>
```{python,warning=F,message=F}
# Generate random numbers from a Normal(5, 2)
normals = np.random.normal(loc=5, scale=2, size=5000)

# Print normals
print(normals)
```

<li>Plot a histogram of <code>uniforms</code> with bins of width of <code>0.25</code> from <code>-3</code> to <code>3</code> using pandas <code>.hist()</code>.</li>
```{python,warning=F,message=F}
# Generate random numbers from a Uniform(-3, 3)
uniforms = np.random.uniform(low=-3, high=3, size=5000)

# Plot a histogram of uniform values, binwidth 0.25
plt.hist(uniforms, bins=np.arange(-3, 3.25, 0.25))
plt.show()
```

<li>Plot a histogram of <code>normals</code> with bins of width of <code>0.5</code> from <code>-2</code> to <code>13</code> using pandas <code>.hist()</code>.</li>

```{python,warning=F,message=F}
# Generate random numbers from a Normal(5, 2)
normals = np.random.normal(loc=5, scale=2, size=5000)

# Plot a histogram of normal values, binwidth 0.5
plt.hist(normals, bins=np.arange(-2, 13.5, 0.5))
plt.show()
```

<p class="">Hunky-dory histogramming! Notice how the histograms almost take the flat and bell curve shapes of the uniform and normal distributions, but there is a bit of random noise.</p>

### Understanding random seeds

<div class>
<p>While random numbers are important for many analyses, they create a problem: the results you get can vary slightly. This can cause awkward conversations with your boss when your script for calculating the sales forecast gives different answers each time. </p>
<p>Setting the seed for <code>numpy</code>'s random number generator helps avoid such problems by making the random number generation reproducible.</p>
</div>

<div class=""><p>Which statement about <code>x</code> and <code>y</code> is true?</p>
<pre><code>import numpy as np
np.random.seed(123)
x = np.random.normal(size=5)
y = np.random.normal(size=5)
</code></pre></div>

<li><code>x</code> and <code>y</code> have identical values.</li>
<li>The first value of <code>x</code> is identical to the first value of <code>y</code>, but other values are different.</li>
<strong><li>The values of <code>x</code> are different from those of <code>y</code>.</li></strong>

<div class=""><p>Which statement about <code>x</code> and <code>y</code> is true?</p>
<pre><code>import numpy as np
np.random.seed(123)
x = np.random.normal(size=5)
np.random.seed(123)
y = np.random.normal(size=5)
</code></pre></div>

<strong><li><code>x</code> and <code>y</code> have identical values.</li></strong>
<li>The first value of <code>x</code> is identical to the first value of <code>y</code>, but other values are different.</li>
<li>The values of <code>x</code> are different from those of <code>y</code>.</li>

<div class=""><p>Which statement about <code>x</code> and <code>y</code> is true?</p>
<pre><code>import numpy as np
np.random.seed(123)
x = np.random.normal(size=5)
np.random.seed(456)
y = np.random.normal(size=5)
</code></pre></div>

<li><code>x</code> and <code>y</code> have identical values.</li>
<li>The first value of <code>x</code> is identical to the first value of <code>y</code>, but other values are different.</li>
<strong><li>The values of <code>x</code> are different from those of <code>y</code>.</li></strong>

<p class="">Correct! Since different seeds are used, the generation will be different for <code>x</code> and <code>y</code>.</p>

# Don't get theory eyed

<p class="chapter__description">
    It’s time to get hands-on and perform the four random sampling methods in Python: simple, systematic, stratified, and cluster.
  </p>
  
## Simple is as simple does



### Simple random sampling


<div class>
<p>The simplest method of sampling a population is the one you've seen already. It is known as <em>simple random sampling</em> (sometimes abbreviated to "SRS"), and involves picking rows at random, one at a time, where each row has the same chance of being picked as any other. </p>
<p>In this chapter, you'll apply sampling methods to a synthetic (fictional) employee attrition dataset from IBM, where "attrition" in this context means leaving the company.</p>
<p><code>attrition_pop</code> is available; <code>pandas</code> as <code>pd</code> is loaded.</p>
</div>
```{python,warning=F,message=F}

attrition_pop = pd.read_feather('https://assets.datacamp.com/production/repositories/5975/datasets/3ca1b1a6e25d960f872dcee7cde666d57680bae0/attrition.feather')
```

<li>Sample 70 rows from <code>attrition_pop</code> using simple random sampling, setting the random seed to <code>18900217</code>.</li>
```{python,warning=F,message=F}
# Sample 70 rows using simple random sampling and set the seed
attrition_samp = attrition_pop.sample(n=70, random_state=18900217)
```
<li>Print the sample dataset, <code>attrition_samp</code>. <em>What do you notice about the indices?</em>
</li>
```{python,warning=F,message=F}
# Print the sample
print(attrition_samp)
```

<p class="">Simply the best! Notice how the indexes in the sample aren't always in increasing order. They are just random.</p>

### Systematic sampling


<div class>
<p>One sampling method that avoids randomness is called <em>systematic sampling</em>. Here, you pick rows from the population at regular intervals.</p>
<p>For example, if the population dataset had one thousand rows, and you wanted a sample size of five, you could pick rows <code>0</code>, <code>200</code>, <code>400</code>, <code>600</code>, and <code>800</code>.</p>
<p><code>attrition_pop</code> is available; <code>pandas</code> has been pre-loaded as <code>pd</code>.</p>
</div>

<li>Set the sample size to <code>70</code>.</li>
```{python,warning=F,message=F}
# Set the sample size to 70
sample_size = 70
```
<li>Calculate the population size from <code>attrition_pop</code>.</li>
```{python,warning=F,message=F}
# Calculate the population size from attrition_pop
pop_size = len(attrition_pop)
```
<li>Calculate the interval between the rows to be sampled.</li>
```{python,warning=F,message=F}
# Calculate the interval
interval = pop_size // sample_size
```

<li>Systematically sample <code>attrition_pop</code> to get the rows of the population at each <code>interval</code>, starting at 0; assign the rows to <code>attrition_sys_samp</code>.</li>
```{python,warning=F,message=F}
# Systematically sample 70 rows
attrition_sys_samp = attrition_pop.iloc[::interval]

# Print the sample
print(attrition_sys_samp)
```

<p class="">Systematic success! Systematic sampling avoids randomness by picking rows at regular intervals.</p>

### Is systematic sampling OK?


<div class>
<p>Systematic sampling has a problem: if the data has been sorted, or there is some sort of pattern or meaning behind the row order, then the resulting sample may not be representative of the whole population. The problem can be solved by shuffling the rows, but then systematic sampling is equivalent to simple random sampling.</p>
<p>Here you'll look at how to determine whether or not there is a problem.</p>
<p><code>attrition_pop</code> is available; <code>pandas</code>  is loaded as <code>pd</code>, and <code>matplotlib.pyplot</code> as <code>plt</code>.</p>
</div>

<li>Add an index column to <code>attrition_pop</code>, assigning the result to <code>attrition_pop_id</code>.</li>
```{python,warning=F,message=F}
# Add an index column to attrition_pop
attrition_pop_id = attrition_pop.reset_index()
```
<li>Create a scatter plot of <code>YearsAtCompany</code> versus <code>index</code> for <code>attrition_pop_id</code>.</li>
```{python,warning=F,message=F}
# Plot YearsAtCompany vs. index for attrition_pop_id
attrition_pop_id.plot(x="index", y="YearsAtCompany", kind="scatter")
plt.show()
```


<li>Randomly shuffle the rows of <code>attrition_pop</code>.</li>
```{python,warning=F,message=F}
# Shuffle the rows of attrition_pop
attrition_shuffled = attrition_pop.sample(frac=1)
```

<li>Reset the row indexes, and add an index column to <code>attrition_pop</code>.</li>
```{python,warning=F,message=F}
# Reset the row indexes and create an index column
attrition_shuffled = attrition_shuffled.reset_index(drop=True).reset_index()
```

<li>Repeat the scatter plot of <code>YearsAtCompany</code> versus <code>index</code>, this time using <code>attrition_shuffled</code>.</li>
```{python,warning=F,message=F}
# Plot YearsAtCompany vs. index for attrition_shuffled
attrition_shuffled.plot(x="index", y="YearsAtCompany", kind="scatter")
plt.show()
```

<div class=""><p>Does a systematic sample always produce a sample similar to a simple random sample?</p></div>

<li>Yes. All sampling (random or non-random) methods will lead us to similar results.</li>
<li>Yes. We should always expect a representative sample for both systematic and simple random sampling.</li>
<li>No. This only holds if a seed has been set for both processes.</li>
<strong><li>No. This is not true if the data is sorted in some way.</li></strong>

<p class="">Your sample skills are ample! Systematic sampling has problems when the data are sorted or contain a pattern. Shuffling the rows makes it equivalent to simple random sampling.</p>

## Can't get no stratisfaction



### Which sampling method?

<div class=""><p>So far, you've learned about several sampling methods, including simple random sampling and stratified sampling. It's important to know when to use each of them.</p></div>

<li>Choose the appropriate sampling method for each situation.</li>

<h5 class="dc-u-ta-center">Stratified sampling</h5>

<p>Demographics matching by race to ensure a census is conducted properly.</p>
<p>Blood types to ensure a vaccine works for different subgroups</p>
<p>Income groups to understand the impact of tax rate changes</p>

<h5 class="dc-u-ta-center">Simple random sampling</h5>
<p>Looking at the distribution of Skittles candy colors, given that the five colors usually appear around 20% of the time.</p>
<p>Not as interested in the properties of a particular subgroup as much as getting a representative sample of the larger group.</p>

<p>Classy classification! Stratified sampling is useful if you care about subgroups. Otherwise, simple random sampling is more appropriate.</p>

### Proportional stratified sampling


<div class>
<p>If you are interested in subgroups within the population, then you may need to carefully control the counts of each subgroup within the population. <em>Proportional stratified sampling</em> results in subgroup sizes within the sample that are representative of the subgroup sizes within the population. It is equivalent to performing a simple random sample on each subgroup.</p>
<p><code>attrition_pop</code> is available; <code>pandas</code> is loaded with its usual alias.</p>
</div>

<li>Get the proportion of employees by <code>Education</code> level from <code>attrition_pop</code>.</li>
```{python,warning=F,message=F}
# Proportion of employees by Education level
education_counts_pop = attrition_pop['Education'].value_counts(normalize=True)

# Print education_counts_pop
print(education_counts_pop)
```

<li>Use proportional stratified sampling on <code>attrition_pop</code> to sample 40% of each <code>Education</code> group, setting the seed to <code>2022</code>.</li>
```{python,warning=F,message=F}
# Proportional stratified sampling for 40% of each Education group
attrition_strat = attrition_pop.groupby('Education')\
	.sample(frac=0.4, random_state=2022)

# Print the sample
print(attrition_strat)
```

<li>Get the proportion of employees by <code>Education</code> level from <code>attrition_strat</code>.</li>
```{python,warning=F,message=F}
# Calculate the Education level proportions from attrition_strat
education_counts_strat = attrition_strat['Education'].value_counts(normalize=True)

# Print education_counts_strat
print(education_counts_strat)
```

<p class="">Perfectly proportioned! By grouping then sampling, the size of each group in the sample is representative of the size of the sample in the population.</p>

### Equal counts stratified sampling


<div class>
<p>If one subgroup is larger than another subgroup in the population, but you don't want to reflect that difference in your analysis, then you can use <em>equal counts stratified sampling</em> to generate samples where each subgroup has the same amount of data. For example, if you are analyzing blood types, O is the most common blood type worldwide, but you may wish to have equal amounts of O, A, B, and AB in your sample.</p>
<p><code>attrition_pop</code> is available; <code>pandas</code> is loaded with its usual alias.</p>
</div>

<li>Use equal counts stratified sampling on <code>attrition_pop</code> to get 30 employees from each <code>Education</code> group, setting the seed to <code>2022</code>.</li>
```{python,warning=F,message=F}
# Get 30 employees from each Education group
attrition_eq = attrition_pop.groupby('Education')\
	.sample(n=30, random_state=2022)      
         
# Print the sample
print(attrition_eq)
```
<li>Get the proportion of employees by <code>Education</code> level from <code>attrition_eq</code>.</li>
```{python,warning=F,message=F}
# Get the proportions from attrition_eq
education_counts_eq = attrition_eq['Education'].value_counts(normalize=True) 

# Print the results
print(education_counts_eq)
```

<p class="">Elegant equal count creation! If you want each subgroup to have equal weight in your analysis, then equal counts stratified sampling is the appropriate technique.</p>

### Weighted sampling


<div class>
<p>Stratified sampling provides rules about the probability of picking rows from your dataset at the subgroup level. A generalization of this is <em>weighted sampling</em>, which lets you specify rules about the probability of picking rows at the row level. The probability of picking any given row is proportional to the weight value for that row.</p>
<p><code>attrition_pop</code> is available; <code>pandas</code>, <code>matplotlib.pyplot</code>, and <code>numpy</code> are loaded with their usual aliases.</p>
</div>

<li>Plot <code>YearsAtCompany</code> from <code>attrition_pop</code> as a histogram with bins of width <code>1</code> from <code>0</code> to <code>40</code>.</li>
```{python,warning=F,message=F}
# Plot YearsAtCompany from attrition_pop as a histogram
attrition_pop['YearsAtCompany'].hist(bins=np.arange(0, 41, 1))
plt.show()
```

<li>Sample 400 employees from <code>attrition_pop</code> weighted by <code>YearsAtCompany</code>.</li>
```{python,warning=F,message=F}
# Sample 400 employees weighted by YearsAtCompany
attrition_weight = attrition_pop.sample(n=400, weights="YearsAtCompany")

# Print the sample
print(attrition_weight)
```

<li>Plot <code>YearsAtCompany</code> from <code>attrition_weight</code> as a histogram with bins of width <code>1</code> from <code>0</code> to <code>40</code>.</li>
```{python,warning=F,message=F}
# Plot YearsAtCompany from attrition_weight as a histogram
attrition_weight['YearsAtCompany'].hist(bins=np.arange(0, 41, 1))
plt.show()
```

<div class=""><p>Which is higher? The mean <code>YearsAtCompany</code> from <code>attrition_pop</code> or the mean <code>YearsAtCompany</code> from <code>attrition_weight</code>?</p></div>

<li>Population mean.</li>
<li>Both means are identical.</li>
<strong><li>Sample mean.</li></strong>
<li>It is impossible to calculate the two means.</li>

<p class="">Marvelous means! The weighted sample mean is around <code>11</code>, which is higher than the population mean of around <code>7</code>. The fact that the two numbers are different means that the weighted simple random sample is biased.</p>

## What a cluster...



### Benefits of clustering

<div class=""><p><em>Cluster sampling</em> is a two-stage sampling technique that is closely related to stratified sampling. First, you randomly sample which subgroups to include in the sample, then randomly sample rows within each subgroup. </p>
<p>In which of the following situations would cluster sampling be preferable to stratified sampling?</p></div>

<li>The interest is on ensuring each rare group will be represented in the sample selected.</li>
<li>Cost is not a limitation, and time can be spent carefully sampling from each group in the population.</li>
<strong><li>Collecting an overall sample requires lots of travel from one group to another to collect samples within each group.</li></strong>
<li>The focus is on comparing particular subgroups within the population.</li>

<p class="dc-completion-pane__message dc-u-maxw-100pc">Delightful decision-making! The main benefit of cluster sampling over stratified sampling is that you can save time and money by not including every subgroup in your sample.</p>

### Cluster sampling


<div class>
<p>Now that you know when to use cluster sampling, it's time to put it into action. In this exercise, you'll explore the <code>JobRole</code> column of the attrition dataset. You can think of each job role as a subgroup of the whole population of employees.</p>
<p><code>attrition_pop</code> is available; <code>pandas</code> is loaded with its usual alias, and the <code>random</code> package is available. A seed of <code>19790801</code> has also been set with <code>random.seed()</code>.</p>
</div>

<li>Create a list of unique <code>JobRole</code> values from <code>attrition_pop</code>, and assign to <code>job_roles_pop</code>.</li>
```{python,warning=F,message=F}
# Create a list of unique JobRole values
job_roles_pop = list(attrition_pop['JobRole'].unique())
```
<li>Randomly sample four <code>JobRole</code> values from <code>job_roles_pop</code>.</li>
```{python,warning=F,message=F}

import random

# Randomly sample four JobRole values
job_roles_samp = random.sample(job_roles_pop, k=4)

# Print the result
print(job_roles_samp)
```

<li>Subset <code>attrition_pop</code> for the sampled job roles by filtering for rows where <code>JobRole</code> is in <code>job_roles_samp</code>.</li>
```{python,warning=F,message=F}
# Filter for rows where JobRole is in job_roles_samp
jobrole_condition = attrition_pop['JobRole'].isin(job_roles_samp)
attrition_filtered = attrition_pop[jobrole_condition]

# Print the result
print(attrition_filtered)
```


<li>Remove any unused categories from <code>JobRole</code>.</li>
```{python,warning=F,message=F}
# Remove categories with no rows
attrition_filtered['JobRole'] = attrition_filtered['JobRole'].cat.remove_unused_categories()
```

<li>For each job role in the filtered dataset, take a random sample of ten rows, setting the seed to <code>2022</code>.</li>
```{python,warning=F,message=F}
# Randomly sample 10 employees from each sampled job role
attrition_clust = attrition_filtered.groupby("JobRole")\
    .sample(n=10, random_state=2022)

# Print the sample
print(attrition_clust)
```

<p class="">Classy cluster sampling! The two-stage sampling technique gives you control over sampling both between subgroups and within subgroups.</p>

## Straight to the point (estimate)



### 3 kinds of sampling


<div class>
<p>You're going to compare the performance of point estimates using simple, stratified, and cluster sampling. Before doing that, you'll have to set up the samples.</p>
<p>You'll use the <code>RelationshipSatisfaction</code> column of the <code>attrition_pop</code> dataset, which categorizes the employee's relationship with the company. It has four levels: <code>Low</code>, <code>Medium</code>, <code>High</code>, and <code>Very_High</code>. <code>pandas</code> has been loaded with its usual alias, and the <code>random</code> package has been loaded.</p>
</div>

<li>Perform simple random sampling on <code>attrition_pop</code> to get one-quarter of the population, setting the seed to <code>2022</code>.</li>
```{python,warning=F,message=F}
# Perform simple random sampling to get 0.25 of the population
attrition_srs = attrition_pop.sample(frac=0.25, random_state=2022)
```



<li>Perform stratified sampling on <code>attrition_pop</code> to sample one-quarter of each <code>RelationshipSatisfaction</code> group, setting the seed to <code>2022</code>.</li>
```{python,warning=F,message=F}
# Perform stratified sampling to get 0.25 of each relationship group
attrition_strat = attrition_pop.groupby("RelationshipSatisfaction")\
    .sample(frac=0.25, random_state=2022)
```


<li>Create a list of unique values from <code>attrition_pop</code>'s <code>RelationshipSatisfaction</code> column.</li>
```{python,warning=F,message=F}
# Create a list of unique RelationshipSatisfaction values
satisfaction_unique = list(attrition_pop['RelationshipSatisfaction'].unique())
```
<li>Randomly sample <code>satisfaction_unique</code> to get two values.</li>
```{python,warning=F,message=F}
# Randomly sample 2 unique satisfaction values
satisfaction_samp = random.sample(satisfaction_unique, k=2)
```
<li>Subset the population for rows where <code>RelationshipSatisfaction</code> is in <code>satisfaction_samp</code> and clear any unused categories from <code>RelationshipSatisfaction</code>; assign to <code>attrition_clust_prep</code>.</li>
```{python,warning=F,message=F}
# Filter for satisfaction_samp and clear unused categories from RelationshipSatisfaction
satis_condition = attrition_pop['RelationshipSatisfaction'].isin(satisfaction_samp)
attrition_clust_prep = attrition_pop[satis_condition]
attrition_clust_prep['RelationshipSatisfaction'] = attrition_clust_prep['RelationshipSatisfaction'].cat.remove_unused_categories()
```
<li>Perform cluster sampling on the selected satisfaction groups, sampling one quarter of the <em>population</em> and setting the seed to <code>2022</code>.</li>
```{python,warning=F,message=F}
# Perform cluster sampling on the selected group, getting 0.25 of attrition_pop
attrition_clust = attrition_clust_prep.groupby("RelationshipSatisfaction")\
    .sample(n=len(attrition_pop) // 4, random_state=2022,replace=True)
```

<p class="">Terrific triple! Now we have the three samples set up, let's calculate some summary statistics.</p>

### Comparing point estimates


<div class>
<p>Now that you have three types of sample (simple, stratified, and cluster), you can compare point estimates from each sample to the population parameter. That is, you can calculate the same summary statistic on each sample and see how it compares to the summary statistic for the population.</p>
<p>Here, we'll look at how satisfaction with the company affects whether or not the employee leaves the company. That is, you'll calculate the proportion of employees who left the company (they have an <code>Attrition</code> value of <code>1</code>) for each value of <code>RelationshipSatisfaction</code>.</p>
<p><code>attrition_pop</code>, <code>attrition_srs</code>, <code>attrition_strat</code>, and <code>attrition_clust</code> are available; <code>pandas</code> is loaded with its usual alias.</p>
</div>
<div class="exercise--instructions__content"><p>Group <code>attrition_pop</code> by <code>RelationshipSatisfaction</code> levels and calculate the mean of <code>Attrition</code> for each level.</p></div>
```{python,warning=F,message=F}
# Mean Attrition by RelationshipSatisfaction group
mean_attrition_pop = attrition_pop.groupby('RelationshipSatisfaction')['Attrition'].mean()

# Print the result
print(mean_attrition_pop)
```

<div class="exercise--instructions__content"><p>Calculate the proportion of employee attrition for each relationship satisfaction group, this time on the simple random sample, <code>attrition_srs</code>.</p></div>
```{python,warning=F,message=F}
# Calculate the same thing for the simple random sample 
mean_attrition_srs = attrition_srs.groupby('RelationshipSatisfaction')['Attrition'].mean()

# Print the result
print(mean_attrition_srs)
```

<div class="exercise--instructions__content"><p>Calculate the proportion of employee attrition for each relationship satisfaction group, this time on the stratified sample, <code>attrition_strat</code>.</p></div>
```{python,warning=F,message=F}
# Calculate the same thing for the stratified sample 
mean_attrition_strat = attrition_strat.groupby('RelationshipSatisfaction')['Attrition'].mean()

# Print the result
print(mean_attrition_strat)
```

<div class="exercise--instructions__content"><p>Calculate the proportion of employee attrition for each relationship satisfaction group, this time on the cluster sample, <code>attrition_clust</code>.</p></div>
```{python,warning=F,message=F}
# Calculate the same thing for the cluster sample 
mean_attrition_clust = attrition_clust.groupby('RelationshipSatisfaction')['Attrition'].mean()

# Print the result
print(mean_attrition_clust)
```

<p class="">Super summary statistics! The numbers are all fairly similar, with the notable exception that cluster sampling only gives results for the clusters included in the sample.</p>

# The n's justify the means

<p class="chapter__description">
    Let’s test your sampling. In this chapter, you’ll discover how to quantify the accuracy of sample statistics using relative errors, and measure variation in your estimates by generating sampling distributions.
  </p>
  
## An ample sample



### Calculating relative errors


<div class>
<p>The size of the sample you take affects how accurately the point estimates reflect the corresponding population parameter. For example, when you calculate a sample mean, you want it to be close to the population mean. However, if your sample is too small, this might not be the case.</p>
<p>The most common metric for assessing accuracy is <em>relative error</em>. This is the absolute difference between the population parameter and the point estimate, all divided by the population parameter. It is sometimes expressed as a percentage.</p>
<p><code>attrition_pop</code> and <code>mean_attrition_pop</code> (the mean of the <code>Attrition</code> column of <code>attrition_pop</code>) are available; <code>pandas</code> is loaded as <code>pd</code>.</p>
</div>

<li>Generate a simple random sample from <code>attrition_pop</code> of fifty rows, setting the seed to <code>2022</code>.</li>
```{python,warning=F,message=F}
# Generate a simple random sample of 50 rows, with seed 2022
attrition_srs50 = attrition_pop.sample(n=50, random_state=2022)
```
<li>Calculate the mean employee <code>Attrition</code> in the sample.</li>
```{python,warning=F,message=F}
# Calculate the mean employee attrition in the sample
mean_attrition_srs50 = attrition_srs50['Attrition'].mean()
```
<li>Calculate the relative error between <code>mean_attrition_srs50</code> and <code>mean_attrition_pop</code> as a <em>percentage</em>.</li>
```{python,warning=F,message=F}
# Calculate the relative error percentage
rel_error_pct50 = 100 * abs(mean_attrition_pop-mean_attrition_srs50) / mean_attrition_pop

# Print rel_error_pct50
print(rel_error_pct50)
```



<li>Calculate the <em>relative error percentage</em> again. This time, use a simple random sample of one hundred rows of <code>attrition_pop</code>.</li>
```{python,warning=F,message=F}
# Generate a simple random sample of 100 rows, with seed 2022
attrition_srs100 = attrition_pop.sample(n=100, random_state=2022)

# Calculate the mean employee attrition in the sample
mean_attrition_srs100 = attrition_srs100['Attrition'].mean()

# Calculate the relative error percentage
rel_error_pct100 = 100 * abs(mean_attrition_pop-mean_attrition_srs100) / mean_attrition_pop

# Print rel_error_pct100
print(rel_error_pct100)
```

<p class="">Samply the best! As you increase the sample size, the sample mean generally gets closer to the population mean, and the relative error decreases.</p>

### Relative error vs. sample size

<div class=""><p>The plot shows the relative error in the proportion of employee attritions, using simple random sampling, for sample sizes from <code>2</code> to <code>1470</code> (the size of the population).</p>
<p>Clicking "Regenerate plot" will select new samples for each sample size, and calculate the relative errors again.</p>
<p>Which statement about relative errors and sample sizes is true?</p></div>

<li>For any given sample size, the relative error between the sample mean and the population mean is fixed at a specific value.</li>
<li>When the sample is as large as the whole population, the relative error is small, but never zero.</li>
<li>If the sample mean is greater than the population mean, the relative error can be less than zero.</li>
<li>The relative error can never be greater than 100%.</li>
<strong><li>For small sample sizes, each additional entry in a sample can result in substantial decreases to the relative error.</li></strong>

<p class="dc-completion-pane__message dc-u-maxw-100pc">You're relatively great at this! As you increase the sample size, the relative error decreases quickly at first, then more slowly as it drops to zero.</p>

## Baby back dist-rib-ution



### Replicating samples


<div class>
<p>When you calculate a point estimate such as a sample mean, the value you calculate depends on the rows that were included in the sample. That means that there is some randomness in the answer. In order to quantify the variation caused by this randomness, you can create many samples and calculate the sample mean (or another statistic) for each sample.</p>
<p><code>attrition_pop</code> is available; <code>pandas</code> and <code>matplotlib.pyplot</code> are loaded with their usual aliases.</p>
</div>

<li>Replicate the provided code so that it runs <code>500</code> times. Assign the resulting list of sample means to <code>mean_attritions</code>.</li>
```{python,warning=F,message=F}
# Create an empty list
mean_attritions = []
# Loop 500 times to create 500 sample means
for i in range(500):
	mean_attritions.append(
    	attrition_pop.sample(n=60)['Attrition'].mean()
	)
  
# Print out the first few entries of the list
print(mean_attritions[0:5])
```

<li>Draw a histogram of the <code>mean_attritions</code> list with 16 bins.</li>
```{python,warning=F,message=F}
# Create a histogram of the 500 sample means
plt.hist(mean_attritions, bins=16)
plt.show()
```

<p class="">Resplendent replicating! By generating the sample statistic many times with different samples, you can quantify the amount of variation in those statistics.</p>

### Replication parameters

<div class=""><p>The dashboard shows a histogram of sample mean proportions of employee attrition. There are two parameters: the size of each simple random sample, and the number of replicates. It's important to understand how each of these parameters affects the result. <em>Use the parameter sliders to explore different values and note their effect on the histogram.</em></p>
<p>Which statement about the effect of each parameter on the distribution of sample means is true?</p></div>

<li>As the sample size increases, the range of calculated sample means tends to increase.</li>
<li>As the number of replicates increases, the range of calculated sample means tends to increase.</li>
<strong><li>As the sample size increases, the range of calculated sample means tends to decrease.</li></strong>
<li>As the number of replicates increases, the range of calculated sample means tends to decrease.</li>

<p class="dc-completion-pane__message dc-u-maxw-100pc">Powerful parameter play! As sample size increases, on average each sample mean has a lower relative error compared to the population mean, thus reducing the range of the distribution.</p>

## Put samples to the test



### Exact sampling distribution


<div class>
<p>To quantify how the point estimate (sample statistic) you are interested in varies, you need to know all the possible values it can take and how often. That is, you need to know its distribution.</p>
<p>The distribution of a sample statistic is called the <em>sampling distribution</em>. When we can calculate this exactly, rather than using an approximation, it is known as the <em>exact sampling distribution</em>.</p>
<p>Let's take another look at the sampling distribution of dice rolls. This time, we'll look at five eight-sided dice. (These have the numbers one to eight.)</p>
<p><img src="https://assets.datacamp.com/production/repositories/5975/datasets/001ee1102f4838b0806d9b3592ce76ce454c3892/shutterstock_231673213_8_sided_die.jpeg" alt="8 sided die"></p>
<p><code>pandas</code>, <code>numpy</code>, and <code>matplotlib.pyplot</code> are loaded with their usual aliases. The <code>expand_grid()</code> function is also available, which expects a dictionary of key-value pairs as its argument. The definition of the <code>expand_grid()</code> function is provided in the <a href="https://pandas.pydata.org/pandas-docs/version/0.17.1/cookbook.html#creating-example-data">pandas documentation</a>.</p>
</div>

<li>Expand a grid representing 5 8-sided dice. That is, create a DataFrame with five columns from a dictionary, named <code>die1</code> to <code>die5</code>. The rows should contain all possibilities for throwing five dice, each numbered <code>1</code> to <code>8</code>.</li>
```{python,warning=F,message=F}

import itertools
def expand_grid(data_dict):
    rows = itertools.product(*data_dict.values())
    return pd.DataFrame.from_records(rows, columns=data_dict.keys())
```

```{python,warning=F,message=F}
# Expand a grid representing 5 8-sided dice
dice = expand_grid(
  {'die1': [1, 2, 3, 4, 5, 6, 7, 8],
   'die2': [1, 2, 3, 4, 5, 6, 7, 8],
   'die3': [1, 2, 3, 4, 5, 6, 7, 8],
   'die4': [1, 2, 3, 4, 5, 6, 7, 8],
   'die5': [1, 2, 3, 4, 5, 6, 7, 8]
  })

# Print the result
print(dice)
```

<li>Add a column, <code>mean_roll</code>, to <code>dice</code>, that contains the mean of the five rolls as a categorical.</li>
```{python,warning=F,message=F}
# Add a column of mean rolls and convert to a categorical
dice['mean_roll'] = (dice['die1'] + dice['die2'] + 
                     dice['die3'] + dice['die4'] + 
                     dice['die5']) / 5
dice['mean_roll'] = dice['mean_roll'].astype('category')

# Print result
print(dice)
```

<li>Create a bar plot of the <code>mean_roll</code> categorical column, so it displays the count of each <code>mean_roll</code> in increasing order from <code>1.0</code> to <code>8.0</code>.</li>

```{python,warning=F,message=F}
# Draw a bar plot of mean_roll
dice['mean_roll'].value_counts(sort=False).plot(kind="bar")
plt.show()
```

<p class="">Exactly right! The exact sampling distribution shows all possible variations of the point estimate that you are interested in.</p>

### Approximate sampling distribution

<div class>
<p>Calculating the exact sampling distribution is only possible in very simple situations. With just five eight-sided dice, the number of possible rolls is <code>8**5</code>, which is over thirty thousand. When the dataset is more complicated, for example, where a variable has hundreds or thousands of categories, the number of possible outcomes becomes too difficult to compute exactly.</p>
<p>In this situation, you can calculate an <em>approximate sampling distribution</em> by simulating the exact sampling distribution. That is, you can repeat a procedure over and over again to simulate both the sampling process and the sample statistic calculation process.</p>
<p><code>pandas</code>, <code>numpy</code>, and <code>matplotlib.pyplot</code> are loaded with their usual aliases.</p>
</div>

<li>Sample one to eight, five times, with replacement. Assign to <code>five_rolls</code>.</li>
```{python,warning=F,message=F}
# Sample one to eight, five times, with replacement
five_rolls = np.random.choice(list(range(1, 9)), size=5, replace=True)
```
<li>Calculate the mean of <code>five_rolls</code>.</li>
```{python,warning=F,message=F}
# Print the mean of five_rolls
print(five_rolls.mean())
```

<li>Replicate the sampling code 1000 times, assigning each result to the list <code>sample_means_1000</code>.</li>
```{python,warning=F,message=F}
# Replicate the sampling code 1000 times
sample_means_1000 = []
for i in range(1000):
    sample_means_1000.append(
  		np.random.choice(list(range(1, 9)), size=5, replace=True).mean()
    )

# Print the first 10 entries of the result
print(sample_means_1000[0:10])
```

<li>Plot <code>sample_means_1000</code> as a histogram with <code>20</code> bins.</li>
```{python,warning=F,message=F}
# Draw a histogram of sample_means_1000 with 20 bins
plt.hist(sample_means_1000, bins=20)
plt.show()
```

<p class="">Applaudable approximating! Once your dataset gets sufficiently big, exact sampling distributions cannot be calculated, so an approximate sampling distribution must be used. Notice that the histogram is close to but not exactly the same as the shape of the bar graph from the previous exercise.</p>

### Exact vs. approximate

<div class=""><p>You've seen two types of sampling distribution now (exact and approximate). It's really important to understand when each should be computed. </p>
<p>Should we always be able to compute the exact sampling distribution directly?</p></div>

<li>No, the exact sampling distribution is always unknown even for calculating the sample mean of a small number of die tosses like 2 or 3.</li>
<li>Yes, the population will always be known ahead of time, so one extra calculation is no problem.</li>
<li>Yes, the exact sampling distribution can be generated using a <code>for</code> loop, so it should be possible in all circumstances.</li>
<strong><li>No, the computational time and resources needed to look at the population of values could be too much for our problem.</li></strong>

<p class="dc-completion-pane__message dc-u-maxw-100pc">Delightful sampling distribution distinguishing! The exact sampling distribution can only be calculated if you know what the population is and if the problems are small and simple enough to compute. Otherwise, the approximate sampling distribution must be used.</p>

## Err on the side of Gaussian



### Population &amp; sampling distribution means


<div class>
<p>One of the useful features of sampling distributions is that you can quantify them. Specifically, you can calculate summary statistics on them. Here, you'll look at the relationship between the mean of the sampling distribution and the population parameter's mean.</p>
<p>Three sampling distributions are provided. For each, the employee attrition dataset was sampled using simple random sampling, then the mean attrition was calculated. This was done 1000 times to get a sampling distribution of mean attritions. One sampling distribution used a sample size of 5 for each replicate, one used 50, and one used 500.</p>
<p><code>attrition_pop</code>, <code>sampling_distribution_5</code>, <code>sampling_distribution_50</code>, and <code>sampling_distribution_500</code> are available; <code>numpy</code> as <code>np</code> is loaded.</p>
</div>
```{python,warning=F,message=F}

sampling_distribution = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vRap3kWpwEhSDTpqc_LrCbTQIY9qLhnpZP17axDfsGUSOV6DL_fJsqNp9vXbCAjfzrBds8c3NCJZg2f/pub?gid=401876436&single=true&output=csv')
sampling_distribution_5 = sampling_distribution['five']
sampling_distribution_50 = sampling_distribution['fifty']
sampling_distribution_500 = sampling_distribution['five_hundred']
```

<li>Calculate the mean of <code>sampling_distribution_5</code>, <code>sampling_distribution_50</code>, and <code>sampling_distribution_500</code> (a mean of sample means).</li>
```{python,warning=F,message=F}
# Calculate the mean of the mean attritions for each sampling distribution
mean_of_means_5 = np.mean(sampling_distribution_5)
mean_of_means_50 = np.mean(sampling_distribution_50)
mean_of_means_500 = np.mean(sampling_distribution_500)

# Print the results
print(mean_of_means_5)
print(mean_of_means_50)
print(mean_of_means_500)
```

<p>How does sample size affect the mean of the sample means?</p>

<li>As the sample size increases, the mean of the sampling distribution decreases until it reaches the population mean.</li>
<li>As the sample size increases, the mean of the sampling distribution increases until it reaches the population mean.</li>
<strong><li>Regardless of sample size, the mean of the sampling distribution is a close approximation to the population mean.</li></strong>
<li>Regardless of sample size, the mean of the sampling distribution is biased and cannot approximate the population mean.</li>

<p class="">Mind-blowing mean manipulation! Even for small sample sizes, the mean of the sampling distribution is a good approximation of the population mean.</p>

### Population &amp; sampling distribution variation


<div class>
<p>You just calculated the mean of the sampling distribution and saw how it is an estimate of the corresponding population parameter. Similarly, as a result of the central limit theorem, the standard deviation of the sampling distribution has an interesting relationship with the population parameter's standard deviation and the sample size.</p>
<p><code>attrition_pop</code>, <code>sampling_distribution_5</code>, <code>sampling_distribution_50</code>, and <code>sampling_distribution_500</code> are available; <code>numpy</code> is loaded with its usual alias.</p>
</div>

<li>Calculate the standard deviation of <code>sampling_distribution_5</code>, <code>sampling_distribution_50</code>, and <code>sampling_distribution_500</code> (a standard deviation of sample means).</li>
```{python,warning=F,message=F}
# Calculate the std. dev. of the mean attritions for each sampling distribution
sd_of_means_5 = np.std(sampling_distribution_5, ddof=1)
sd_of_means_50 = np.std(sampling_distribution_50, ddof=1)
sd_of_means_500 = np.std(sampling_distribution_500, ddof=1)

# Print the results
print(sd_of_means_5)
print(sd_of_means_50)
print(sd_of_means_500)
```

<p>How are the standard deviations of the sampling distributions related to the population standard deviation and the sample size?</p>

<li>The standard deviation of the sampling distribution is approximately equal to the population standard deviation, regardless of sample size.</li>
<li>The standard deviation of the sampling distribution is approximately equal to the population standard deviation multiplied by the sample size.</li>
<li>The standard deviation of the sampling distribution is approximately equal to the population standard deviation multiplied by the square root of the sample size.</li>
<li>The standard deviation of the sampling distribution is approximately equal to the population standard deviation divided by the sample size.</li>
<strong><li>The standard deviation of the sampling distribution is approximately equal to the population standard deviation divided by the square root of the sample size.</li></strong>

<p class="">You set the gold standard for standard deviation! The amount of variation in the sampling distribution is related to the amount of variation in the population and the sample size. This is another consequence of the Central Limit Theorem.</p>

# Pull Your Data Up By Its Bootstraps

<p class="chapter__description">
    You’ll get to grips with resampling to perform bootstrapping and estimate variation in an unknown population. You’ll learn the difference between sampling distributions and bootstrap distributions using resampling.
  </p>
  
## Striking resample-lance



### Principles of bootstrapping

<div class=""><p><em>Bootstrapping</em> is, in some sense, the opposite of sampling from a population. Sampling treats your dataset as the population, and you generate a random subset. Bootstrapping treats your dataset as a sample and uses it to build up a theoretical population.</p></div>

<p>Which statements about bootstrapping are true?</p>

<h5 class="dc-u-ta-center">True</h5>
<p>Bootstrap resamples should be the same size as the original sample.</p>
<p>Each row in the dataset should have an equally likely chance of being drawn in a resample.</p>
<p>A bootstrap distribution consists of many replicates of the statistic of interest.</p>

<h5 class="dc-u-ta-center">False</h5>
<p>Resampling means sampling without replacement.</p>
<p>Bootstrap samples should be smaller than the original sample.</p>
<p>The statistic of interest for each bootstrap sample is always the mean.</p>
<p>A bootstrap distribution is the same thing as a sampling distribution.</p>

<p>Brilliant bootstrapping! The bootstrapping workflow is to generate a resample of the same size as the population, calculate a summary statistic, then repeat this to get a distribution of summary statistics.</p>

### With or without replacement?

<div class=""><p>So far in the course, you've seen sampling with and without replacement. It's important to know when to use each method.</p></div>

<p>Read the different scenarios and determine whether sampling without replacement from a population or sampling with replacement from a sample is the most appropriate strategy.</p>

<h5 class="dc-u-ta-center">With replacement</h5>

<p>While studying variability in tigers' weights, you collected data on 10 tigers. You suspect that there are around 50 in your region of Siberia.</p>
<p>A small hedge fund lacks the resources to track every stock, but feels confident that the 100 stocks they have tracked represent the market.</p>

<h5 class="dc-u-ta-center">Without replacement</h5>
<p>A small hedge fund lacks the resources to track every stock, but feels confident that the 100 stocks they have tracked represent the market.</p>
<p>A social media company released all their members' posts from the last year. You need to report on this data to your manager by the end of the week.</p>

<p>Radical replacement reasoning! The key to deciding whether to sample without or with replacement is whether or not your dataset is best thought of as being the whole population or not.</p>

### Generating a bootstrap distribution


<div class>
<p>The process for generating a bootstrap distribution is similar to the process for generating a sampling distribution; only the first step is different.</p>
<p>To make a sampling distribution, you start with the population and sample without replacement. To make a bootstrap distribution, you start with a sample and sample that with replacement. After that, the steps are the same: calculate the summary statistic that you are interested in on that sample/resample, then replicate the process many times. In each case, you can visualize the distribution with a histogram.</p>
<p>Here, <code>spotify_sample</code> is a subset of the <code>spotify_population</code> dataset. To make it easier to see how resampling works, a row index column called <code>'index'</code> has been added, and only the artist name, song name, and <code>danceability</code> columns have been included.</p>
<p><code>spotify_sample</code> is available; <code>pandas</code>, <code>numpy</code>, and <code>matplotlib.pyplot</code> are loaded with their usual aliases.</p>
</div>

<li>Generate a single bootstrap resample from <code>spotify_sample</code>.</li>
```{python,warning=F,message=F}
# Generate 1 bootstrap resample
spotify_1_resample = spotify_sample.sample(frac=1, replace=True)

# Print the resample
print(spotify_1_resample)
```

<li>Calculate the mean <code>danceability</code> of <code>spotify_1_resample</code> as <code>mean_danceability_1</code>, using <code>numpy</code>.</li>
```{python,warning=F,message=F}
# Calculate mean danceability of resample
mean_danceability_1 = np.mean(spotify_1_resample['danceability'])

# Print the result
print(mean_danceability_1)
```

<li>Replicate the expression provided 1000 times.</li>
```{python,warning=F,message=F}
# Replicate this 1000 times
mean_danceability_1000 = []
for i in range(1000):
	mean_danceability_1000.append(
        np.mean(spotify_sample.sample(frac=1, replace=True)['danceability'])
	)
  
# Print the result
print(mean_danceability_1000)
```

<li>Create a bootstrap distribution by drawing a histogram of <code>mean_danceability_1000</code>.</li>
## A breath of fresh error
```{python,warning=F,message=F}
# Draw a histogram of the resample means
plt.hist(mean_danceability_1000)
plt.show()
```

<p class="">Beautiful bootstrapping! From the smaller sample of Spotify songs, we can estimate the mean danceability statistic in the population. Since we have a distribution of statistics, we can even quantify how accurate our estimate is.</p>

### Bootstrap statistics and population statistics

<div class=""><p>Bootstrap distribution statistics can be used to estimate population parameters. But can you always rely on them to give an accurate estimate of an unknown population parameter?</p>
<p>Should the mean and the standard deviation of the bootstrap distribution both be used to estimate the corresponding values of the population?</p></div>

<li>No, the standard deviation of the bootstrap distribution divided by the square root of the sample size will tend to be near the sample standard deviation, which may not necessarily be very close to the population standard deviation.</li>
<li>Yes, both estimates should match up closely with the population values in all scenarios.</li>
<strong><li>No, the mean of the bootstrap distribution will always be near the sample mean, which may not necessarily be very close to the population mean.</li></strong>
<strong><li>Yes, the variability of the sample, the population, the bootstrap distribution, and the sampling distribution will all be similar regardless of the sample size selected.</li></strong>

<p class="dc-completion-pane__message dc-u-maxw-100pc">Super standard error reasoning! If the sample is not closely representative of the population, then the mean of the bootstrap distribution will not be representative of the population mean. This is less of a problem for standard errors.</p>

### Sampling distribution vs. bootstrap distribution


<div class>
<p>The sampling distribution and bootstrap distribution are closely linked. In situations where you can repeatedly sample from a population (these occasions are rare), it's helpful to generate both the sampling distribution and the bootstrap distribution, one after the other, to see how they are related.</p>
<p>Here, the statistic you are interested in is the mean <code>popularity</code> score of the songs.</p>
<p><code>spotify_population</code> (the whole dataset) and <code>spotify_sample</code> (<code>500</code> randomly sampled rows from <code>spotify_population</code>) are available; <code>pandas</code> and <code>numpy</code> are loaded with their usual aliases.</p>
</div>

<li>Generate a sampling distribution of 2000 replicates.</li>
```{python,warning=F,message=F}

```
<li>Sample 500 rows of the population without replacement and calculate the mean <code>popularity</code>.</li>
```{python,warning=F,message=F}
mean_popularity_2000_samp = []

# Generate a sampling distribution of 2000 replicates
for i in range(2000):
    mean_popularity_2000_samp.append(
    	# Sample 500 rows and calculate the mean popularity     
    	spotify_population.sample(n=500)['popularity'].mean()
    )

# Print the sampling distribution results
print(mean_popularity_2000_samp)
```


<li>Generate a bootstrap distribution of 2000 replicates.</li>
```{python,warning=F,message=F}

```
<li>Sample 500 rows of the sample with replacement and calculate the mean <code>popularity</code>.</li>
```{python,warning=F,message=F}
mean_popularity_2000_boot = []

# Generate a bootstrap distribution of 2000 replicates
for i in range(2000):
    mean_popularity_2000_boot.append(
    	# Resample 500 rows and calculate the mean popularity
    	spotify_sample.sample(n=500, replace=True)['popularity'].mean()
    )

# Print the bootstrap distribution results
print(mean_popularity_2000_boot)
```

<p class="">Dazzling distributions! The sampling distribution and bootstrap distribution are closely related, and so is the code to generate them.</p>

### Compare sampling and bootstrap means


<div class>
<p>To make calculation easier, distributions similar to those calculated from the previous exercise have been included, this time using a sample size of <code>5000</code>.</p>
<p><code>spotify_population</code>, <code>spotify_sample</code>, <code>sampling_distribution</code>, and <code>bootstrap_distribution</code> are available; <code>pandas</code> and <code>numpy</code> are loaded with their usual aliases.</p>
</div>
<div class="exercise--instructions__content">
<p>Calculate the mean <code>popularity</code> in 4 ways:</p>

<li>Population: from <code>spotify_population</code>, take the mean of <code>popularity</code>.</li>
```{python,warning=F,message=F}
# Calculate the population mean popularity
pop_mean = spotify_population['popularity'].mean()
```
<li>Sample: from <code>spotify_sample</code>, take the mean of <code>popularity</code>.</li>
```{python,warning=F,message=F}
# Calculate the original sample mean popularity
samp_mean = spotify_sample['popularity'].mean()
```
<li>Sampling distribution: from <code>sampling_distribution</code>, take its mean.</li>
```{python,warning=F,message=F}
# Calculate the sampling dist'n estimate of mean popularity
samp_distn_mean = np.mean(sampling_distribution)
```
<li>Bootstrap distribution: from <code>bootstrap_distribution</code>, take its mean.</li>
```{python,warning=F,message=F}


bootstrap_distribution = []

# Generate a bootstrap distribution of 2000 replicates
for i in range(5000):
    bootstrap_distribution.append(
    	# Resample 500 rows and calculate the mean popularity
    	spotify_sample.sample(n=500, replace=True)['popularity'].mean()
    )

# Calculate the bootstrap dist'n estimate of mean popularity
boot_distn_mean = np.mean(bootstrap_distribution)

# Print the means
print([pop_mean, samp_mean, samp_distn_mean, boot_distn_mean])
```

</div>

<p>Based on the four means you just calculated (<code>pop_mean</code>, <code>samp_mean</code>, <code>samp_distn_mean</code>, and <code>boot_distn_mean</code>), which statement is true?</p>

<li>The sampling distribution mean is closest to the original sample mean; the bootstrap distribution mean is the best estimate of the true population mean.</li>
<strong><li>The sampling distribution mean is the best estimate of the true population mean; the bootstrap distribution mean is closest to the original sample mean.</li></strong>
<li>The sampling distribution mean and the bootstrap distribution mean are equally good estimates of the original sample mean.</li>
<li>The sampling distribution mean and the bootstrap distribution mean are equally good estimates of the true population mean.</li>

<p class="">Magnificent means! The sampling distribution mean can be used to estimate the population mean, but that is not the case with the bootstrap distribution.</p>

### Compare sampling and bootstrap standard deviations


<div class>
<p>In the same way that you looked at how the sampling distribution and bootstrap distribution could be used to estimate the population mean, you'll now take a look at how they can be used to estimate variation, or more specifically, the standard deviation, in the population. </p>
<p>Recall that the sample size is <code>5000</code>.</p>
<p><code>spotify_population</code>, <code>spotify_sample</code>, <code>sampling_distribution</code>, and <code>bootstrap_distribution</code> are available; <code>pandas</code> and <code>numpy</code> are loaded with their usual aliases.</p>
</div>
<div class="exercise--instructions__content">
<p>Calculate the standard deviation of <code>popularity</code> in 4 ways.</p>

<li>Population: from <code>spotify_population</code>, take the standard deviation of <code>popularity</code>.</li>
```{python,warning=F,message=F}
# Calculate the population std dev popularity
pop_sd = spotify_population['popularity'].std(ddof=0)
```
<li>Original sample: from <code>spotify_sample</code>, take the standard deviation of <code>popularity</code>.</li>
```{python,warning=F,message=F}
# Calculate the original sample std dev popularity
samp_sd = spotify_sample['popularity'].std()
```
<li>Sampling distribution: from <code>sampling_distribution</code>, take its standard deviation and multiply by the square root of the sample size (<code>5000</code>).</li>
```{python,warning=F,message=F}
# Calculate the sampling dist'n estimate of std dev popularity
samp_distn_sd = np.std(sampling_distribution, ddof=1) * np.sqrt(5000)
```
<li>Bootstrap distribution: from <code>bootstrap_distribution</code>, take its standard deviation and multiply by the square root of the sample size.</li>
```{python,warning=F,message=F}
# Calculate the bootstrap dist'n estimate of std dev popularity
boot_distn_sd = np.std(bootstrap_distribution, ddof=1) * np.sqrt(5000)

# Print the standard deviations
print([pop_sd, samp_sd, samp_distn_sd, boot_distn_sd])
```

</div>

<p>Based on the four results you just calculated (<code>pop_sd</code>, <code>samp_sd</code>, <code>samp_distn_sd</code>, and <code>boot_distn_sd</code>), which statement is true?</p>

<strong><li>The calculation from the bootstrap distribution is the best estimate of the population standard deviation.</li></strong>
<li>The calculation from the sampling distribution is the best estimate of the population standard deviation.</li>
<li>The calculation from the sample is the best estimate of the population standard deviation.</li>
<li>The calculations from both the sampling distribution and from the bootstrap distribution are equally close to the population standard deviation.</li>

<p class="">Super standard deviations! This is an important property of the bootstrap distribution. When you don't know have all the values from the population or the ability to sample multiple times, you can use bootstrapping to get a good estimate of the population standard deviation.</p>

## Venus infers



### Confidence interval interpretation

<div class=""><p>When reporting results, it is common to provide a confidence interval alongside an estimate.</p>
<p>What information does that confidence interval provide?</p></div>

<li>A range of all possible values that a variable from a sample may take on.</li>
<li>All numbers between 0 and 1.</li>
<li>A range of plausible values for a variable measured in our population (such as <code>popularity</code> in <code>spotify_population</code>).</li>
<strong><li>A range of plausible values for an unknown quantity.</li></strong>

<p class="dc-completion-pane__message dc-u-maxw-100pc">I’m confident you are correct! Confidence intervals account for uncertainty in our estimate of a population parameter by providing a range of possible values. We are confident that the true value lies somewhere in the interval specified by that range.</p>

### Calculating confidence intervals


<div class>
<p>You have learned about two methods for calculating confidence intervals: the <em>quantile method</em> and the <em>standard error method</em>. The standard error method involves using the inverse cumulative distribution function (inverse CDF) of the normal distribution to calculate confidence intervals. In this exercise, you'll perform these two methods on the Spotify data.</p>
<p><code>spotify_population</code>, <code>spotify_sample</code>, and <code>bootstrap_distribution</code> are available; <code>pandas</code> and <code>numpy</code> are loaded with their usual aliases, and <code>norm</code> has been loaded from <code>scipy.stats</code>.</p>
</div>

<li>Generate a 95% confidence interval using the quantile method on the bootstrap distribution, setting the <code>0.025</code> quantile as <code>lower_quant</code> and the <code>0.975</code> quantile as <code>upper_quant</code>.</li>
```{python,warning=F,message=F}
# Generate a 95% confidence interval using the quantile method
lower_quant = np.quantile(bootstrap_distribution, 0.025)
upper_quant = np.quantile(bootstrap_distribution, 0.975)

# Print quantile method confidence interval
print((lower_quant, upper_quant))
```


<div class="exercise--instructions__content">
<p>Generate a 95% confidence interval using the standard error method from the bootstrap distribution.</p>

<li>Calculate <code>point_estimate</code> as the mean of <code>bootstrap_distribution</code>, and <code>standard_error</code> as the standard deviation of <code>bootstrap_distribution</code>.</li>
```{python,warning=F,message=F}
# Find the mean and std dev of the bootstrap distribution
point_estimate = np.mean(bootstrap_distribution)
standard_error = np.std(bootstrap_distribution, ddof=1)
```
<li>Calculate <code>lower_se</code> as the <code>0.025</code> quantile of an inv. CDF from a normal distribution with mean <code>point_estimate</code> and standard deviation <code>standard_error</code>.</li>
```{python,warning=F,message=F}

from scipy.stats import norm
# Find the lower limit of the confidence interval
lower_se = norm.ppf(0.025, loc=point_estimate, scale=standard_error)
```
<li>Calculate <code>upper_se</code> as the <code>0.975</code> quantile of that same inv. CDF.</li>
```{python,warning=F,message=F}
# Find the upper limit of the confidence interval
upper_se = norm.ppf(0.975, loc=point_estimate, scale=standard_error)

# Print standard error method confidence interval
print((lower_se, upper_se))
```

</div>

<p class="">Standard excellence! The standard error method for calculating the confidence interval assumes that the bootstrap distribution is normal. This assumption should hold if the sample size and number of replicates are sufficiently large.</p>